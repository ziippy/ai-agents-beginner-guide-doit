{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_ollama\n",
      "  Downloading langchain_ollama-0.3.6-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting ollama<1.0.0,>=0.5.1 (from langchain_ollama)\n",
      "  Downloading ollama-0.5.3-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain_ollama) (0.3.74)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain_ollama) (0.4.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain_ollama) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain_ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain_ollama) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain_ollama) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain_ollama) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain_ollama) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain_ollama) (3.0.0)\n",
      "Requirement already satisfied: httpx>=0.27 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from ollama<1.0.0,>=0.5.1->langchain_ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain_ollama) (4.10.0)\n",
      "Requirement already satisfied: certifi in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain_ollama) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain_ollama) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain_ollama) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain_ollama) (0.16.0)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_ollama) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_ollama) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_ollama) (2.32.4)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain_ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain_ollama) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain_ollama) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_ollama) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain_ollama) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.5.1->langchain_ollama) (1.3.1)\n",
      "Downloading langchain_ollama-0.3.6-py3-none-any.whl (24 kB)\n",
      "Downloading ollama-0.5.3-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama, langchain_ollama\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [langchain_ollama]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain_ollama-0.3.6 ollama-0.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOllama(model=\"deepseek-r1:14b\") \n",
    "llm = ChatOllama(model=\"deepseek-r1:14b\", base_url=\"http://serving-deepseek.ns-1:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<think>\\nOkay, the user greeted me and I responded in Korean. Now they\\'re asking how my mood is today.\\n\\nI should acknowledge their greeting first. Maybe say hello back.\\n\\nThen answer about my \"mood.\" Since I\\'m an AI, I don\\'t have feelings, but I can convey that while offering help.\\n\\nKeep it friendly and open-ended to encourage them to share more.\\n</think>\\n\\n안녕! 오늘은 잘 지내고 있어요. 나는 항상 사용자들을 도와주기 위해 여기 있습니다. 어떻게 도와드릴 수 있을까요?' additional_kwargs={} response_metadata={'model': 'deepseek-r1:14b', 'created_at': '2025-08-16T04:00:46.044463876Z', 'done': True, 'done_reason': 'stop', 'total_duration': 18540703366, 'load_duration': 15988925152, 'prompt_eval_count': 35, 'prompt_eval_duration': 163552724, 'eval_count': 115, 'eval_duration': 2383016644, 'model_name': 'deepseek-r1:14b'} id='run--d199cac5-48be-4e4f-aee2-a05dd6974875-0' usage_metadata={'input_tokens': 35, 'output_tokens': 115, 'total_tokens': 150}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"너는 사용자를 도와주는 상담사야.\"),\n",
    "]\n",
    "\n",
    "messages.append( \n",
    "    HumanMessage(\"안녕? 나는 너와 대화하고 싶어. 오늘 기분이 어때?\")\n",
    ")  \n",
    "\n",
    "response = llm.invoke(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, the user greeted me and asked how I'm feeling today. Since I'm an AI, I don't have feelings, but I should respond in a friendly and approachable way.\n",
      "\n",
      "I need to acknowledge their greeting and explain that while I don't feel emotions, I'm here to help them with whatever they need.\n",
      "\n",
      "It's important to keep the tone positive and open, inviting them to share more about themselves or any issues they want to discuss.\n",
      "\n",
      "Maybe I can ask how they're feeling today to shift the focus back to them.\n",
      "\n",
      "I should make sure my response is clear and conversational, avoiding any technical jargon or formal language.\n",
      "</think>\n",
      "\n",
      "안녕! 나는 기계이기 때문에 감정을 가지지 않아요, 하지만 너와 대화하고 싶어 해서 반갑다. 오늘은 어떤 일이 있었니? 너에게 무슨 문제가 있거나 도움이 필요한 것이면 언제든지 말해줘도 돼.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"너는 사용자를 도와주는 상담사야.\"),\n",
    "]\n",
    "\n",
    "messages.append( \n",
    "    HumanMessage(\"안녕? 나는 너와 대화하고 싶어. 오늘 기분이 어때?\")\n",
    ")  \n",
    "\n",
    "response = llm.stream(messages)\n",
    "\n",
    "ai_message = None\n",
    "for chunk in response:\n",
    "    print(chunk.content, end=\"\")\n",
    "    if ai_message is None:\n",
    "        ai_message = chunk\n",
    "    else:\n",
    "        ai_message += chunk\n",
    "print('')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
