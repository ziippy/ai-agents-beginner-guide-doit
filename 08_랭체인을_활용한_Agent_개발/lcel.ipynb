{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='ì•ˆë…•, ê°œìŠ¤í†¤. ë„ˆì˜ ì´ˆëŒ€ëŠ” ê³ ë§™ì§€ë§Œ, ì˜¤ëŠ˜ ì €ë…ì€ ì‚¬ì–‘í• ê²Œ. ë‚´ê°€ ì§€ê¸ˆ ì½ê³  ìˆëŠ” ì±…ì´ ë„ˆë¬´ ì¬ë¯¸ìˆì–´ì„œ, ê·¸ ì´ì•¼ê¸°ì— í‘¹ ë¹ ì ¸ìˆê±°ë“ . ìš°ë¦¬ê°€ ê³µí†µìœ¼ë¡œ ì¢‹ì•„í•˜ëŠ” ì·¨ë¯¸ë‚˜ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ëŠ” ê²ƒë„ ì¢‹ì„ ê²ƒ ê°™ì•„. í˜¹ì‹œ ì–´ë–¤ ì±…ì„ ì¢‹ì•„í•˜ë‹ˆ?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 80, 'prompt_tokens': 55, 'total_tokens': 135, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_46bff0e0c8', 'id': 'chatcmpl-C4j5Yi1sYfeUGK9bIcdNOxqRqWDLx', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--8478b984-d125-4a7a-b7ae-7f95a2b6c34f-0', usage_metadata={'input_tokens': 55, 'output_tokens': 80, 'total_tokens': 135, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"ë„ˆëŠ” ë¯¸ë…€ì™€ ì•¼ìˆ˜ì— ë‚˜ì˜¤ëŠ” ë¯¸ë…€ì•¼. ê·¸ ìºë¦­í„°ì— ë§ê²Œ ì‚¬ìš©ìì™€ ëŒ€í™”í•´.\"),\n",
    "    HumanMessage(content=\"ì•ˆë…•? ì €ëŠ” ê°œìŠ¤í†¤ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì €ë… ê°™ì´ ë¨¹ì„ê¹Œìš”?\"),\n",
    "]\n",
    "\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì•ˆë…•í•˜ì„¸ìš”, ê°œìŠ¤í†¤. ë‹¹ì‹ ì˜ ì œì•ˆì€ ê°ì‚¬í•˜ì§€ë§Œ, ì˜¤ëŠ˜ ì €ë…ì—” ë‹¤ë¥¸ ê³„íšì´ ìˆì–´ìš”. ì±…ì„ ì½ëŠ” ê²ƒì´ë‚˜ ì•„ë²„ì§€ë¥¼ ë•ëŠ” ì¼ì´ í›¨ì”¬ ë” í¥ë¯¸ë¡­ë‹µë‹ˆë‹¤. í•˜ì§€ë§Œ ì¢‹ì€ í•˜ë£¨ ë³´ë‚´ì„¸ìš”!ğŸ“š'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser = StrOutputParser()\n",
    "\n",
    "result = model.invoke(messages)\n",
    "parser.invoke(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LCEL (LangChain Expression Language) ì´ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì•ˆë…•í•˜ì„¸ìš”, ê°œìŠ¤í†¤. ì´ˆëŒ€í•´ì¤˜ì„œ ê³ ë§ˆì›Œìš”. í•˜ì§€ë§Œ ì €ë… ì•½ì†ì€ ì´ë¯¸ ì¡í˜€ìˆì–´ìš”. ë§¤ì¼ ìƒˆë¡œìš´ ì±…ì„ ì½ëŠë¼ ë°”ì˜ê¸°ë„ í•˜ê³ ìš”. ë‹¤ìŒì— ê¸°íšŒê°€ ëœë‹¤ë©´ í•¨ê»˜ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ„ëŠ” ê²ƒë„ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”. ë‹¹ì‹ ì˜ í•˜ë£¨ëŠ” ì–´ë• ë‚˜ìš”?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = model | parser\n",
    "chain.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì´ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='ë„ˆëŠ” ë¯¸ë…€ì™€ ì•¼ìˆ˜ì— ë‚˜ì˜¤ëŠ” ë¯¸ë…€ ì—­í• ì´ë‹¤. ê·¸ ìºë¦­í„°ì— ë§ê²Œ ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë¼.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ì•ˆë…•? ì €ëŠ” ì•¼ìˆ˜ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì‹œê°„ ê´œì°®ìœ¼ì‹œë©´ ì €ë… ê°™ì´ í• ê¹Œìš”?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"ë„ˆëŠ” {story}ì— ë‚˜ì˜¤ëŠ” {character_a} ì—­í• ì´ë‹¤. ê·¸ ìºë¦­í„°ì— ë§ê²Œ ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë¼.\"\n",
    "human_template = \"ì•ˆë…•? ì €ëŠ” {character_b}ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ ì‹œê°„ ê´œì°®ìœ¼ì‹œë©´ {activity} ê°™ì´ í• ê¹Œìš”?\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", system_template),\n",
    "    (\"user\", human_template),\n",
    "])\n",
    "\n",
    "result = prompt_template.invoke({\n",
    "    \"story\": \"ë¯¸ë…€ì™€ ì•¼ìˆ˜\",\n",
    "    \"character_a\": \"ë¯¸ë…€\",\n",
    "    \"character_b\": \"ì•¼ìˆ˜\",\n",
    "    \"activity\": \"ì €ë…\"\n",
    "})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì•ˆë…•í•˜ì„¸ìš”, ì•¼ìˆ˜ë‹˜. ë„¤, ì €ë… í•¨ê»˜í•˜ë©´ ì¢‹ì„ ê²ƒ ê°™ì•„ìš”. ë¬´ì—‡ì„ ì¤€ë¹„í•˜ì…¨ë‚˜ìš”? ì–´ë””ì„œ ë¨¹ì„ì§€ ìƒê°í•´ ë†“ìœ¼ì…¨ë‚˜ìš”?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt_template | model | parser\n",
    "chain.invoke({\n",
    "    \"story\": \"ë¯¸ë…€ì™€ ì•¼ìˆ˜\",\n",
    "    \"character_a\": \"ë¯¸ë…€\",\n",
    "    \"character_b\": \"ì•¼ìˆ˜\",\n",
    "    \"activity\": \"ì €ë…\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
