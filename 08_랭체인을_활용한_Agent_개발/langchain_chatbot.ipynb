{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.14-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading orjson-3.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: anyio in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading langsmith-0.4.14-py3-none-any.whl (373 kB)\n",
      "Downloading orjson-3.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "Installing collected packages: zstandard, tenacity, orjson, jsonpointer, requests-toolbelt, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [langchain]10\u001b[0m [langchain]text-splitters]\n",
      "\u001b[1A\u001b[2KSuccessfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.27 langchain-core-0.3.74 langchain-text-splitters-0.3.9 langsmith-0.4.14 orjson-3.11.2 requests-toolbelt-1.0.0 tenacity-9.1.2 zstandard-0.23.0\n",
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.74 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-openai) (0.3.74)\n",
      "Collecting openai<2.0.0,>=1.99.9 (from langchain-openai)\n",
      "  Downloading openai-1.99.9-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Downloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.4.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (25.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.74->langchain-openai) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.74->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.99.9->langchain-openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2025.7.34)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.4)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.74->langchain-openai) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/haiqv/conda/envs/agent-llm/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.5.0)\n",
      "Downloading langchain_openai-0.3.30-py3-none-any.whl (74 kB)\n",
      "Downloading openai-1.99.9-py3-none-any.whl (786 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m786.8/786.8 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tiktoken, openai, langchain-openai\n",
      "\u001b[2K  Attempting uninstall: openai\n",
      "\u001b[2K    Found existing installation: openai 1.99.6\n",
      "\u001b[2K    Uninstalling openai-1.99.6:\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [openai]\n",
      "\u001b[2K      Successfully uninstalled openai-1.99.6━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/3\u001b[0m [openai]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [langchain-openai][openai]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain-openai-0.3.30 openai-1.99.9 tiktoken-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")  # 환경 변수에서 API 키 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='안녕하세요, 김프로님! 무엇을 도와드릴까요?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 15, 'total_tokens': 30, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_ff25b2783a', 'id': 'chatcmpl-C4ckXeDarEed6EvFM52bT71PXur5x', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d99e9263-9569-4aa1-9312-bb101c56c874-0', usage_metadata={'input_tokens': 15, 'output_tokens': 15, 'total_tokens': 30, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"안녕? 나는 김프로야?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='당신을 특정할 수 있는 정보를 제가 가지고 있지 않아서 정확히 누구신지 알 수 없습니다. 하지만 도와드릴 수 있는 부분이 있다면 말씀해 주세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 12, 'total_tokens': 50, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-C4ckmDtrBfOjdvtDmRLd4XhGQK7Hk', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--05f0ac31-7ed1-4c0c-9b68-f58c47157eef-0', usage_metadata={'input_tokens': 12, 'output_tokens': 38, 'total_tokens': 50, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(content=\"내가 누구라고?\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 랭체인으로 멀티턴 대화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 김프로님! 만나서 반갑습니다. 어떻게 도와드릴까요?\n",
      "당신은 \"김프로\"라고 소개해 주셨네요. 어떤 도움이 필요하신지 말씀해 주시면 최선을 다해 도와드리겠습니다!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")  # 환경 변수에서 API 키 가져오기\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"너는 사용자를 도와주는 상담사야.\"),\n",
    "    HumanMessage(content=\"안녕? 나는 김프로야?\"),\n",
    "    AIMessage(content=\"안녕하세요! 네, 당신은 김프로입니다. 프로그래밍을 잘하시고, 친절하고 유머러스한 분이시죠!\"),\n",
    "    HumanMessage(content=\"내가 누구라고?\"),\n",
    "    AIMessage(content=\"당신은 김프로입니다! 프로그래밍을 잘하시고, 친절하고 유머러스한 분이시죠!\")\n",
    "]\n",
    "\n",
    "messages.append(HumanMessage(content=\"안녕? 나는 김프로야.\"))\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)\n",
    "\n",
    "messages.append(response)\n",
    "\n",
    "messages.append(HumanMessage(content=\"내가 누구라고?\"))\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 랭체인 메시지 히스토리 이용해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 김프로님! 어떻게 도와드릴까요?\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory  # 메모리에 대화 기록을 저장하는 클래스\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory  # 메시지 기록을 활용해 실행 가능한 래퍼wrapper 클래스\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# 세션별 대화 기록을 저장할 딕셔너리\n",
    "store = {}\n",
    "\n",
    "# 세션 ID에 따라 대화 기록을 가져오는 함수\n",
    "def get_session_history(session_id: str):\n",
    "    # 만약 해당 세션 ID가 store에 없으면, 새로 생성해 추가함\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()  # 메모리에 대화 기록을 저장하는 객체 생성\n",
    "    return store[session_id]  # 해당 세션의 대화 기록을 반환\n",
    "\n",
    "# 모델 실행 시 대화 기록을 함께 전달하는 래퍼 객체 생성\n",
    "with_message_history = RunnableWithMessageHistory(model, get_session_history)\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}  # 세션 ID를 설정하는 config 객체 생성\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"안녕? 난 김프로야.\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "김프로님이라고 소개하셨는데, 혹시 다른 이름으로 불리길 원하시나요?\n"
     ]
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"내 이름은 뭐라고?\")],\n",
    "    config=config,\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'죄송하지만, 귀하의 이름을 알 수 있는 정보가 제공되지 않았습니다. 어떻게 도와드릴까요?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc3\"}}\n",
    "\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"내 이름이 뭐지?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 스트림 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|죄|송|합니다|.| 대|화|만|으로|는| 사용|자의| 구|체|적인| 국|적|이나| 정|체|성을| 추|론|하는| 것은| 어렵|습니다|.| 특정| 국가|나| 문화|에| 대해| 알고| 싶|다면|,| 그| 나라|를| 직접| 말씀|해| 주|시면| 관련| 정보를| 제공|해| 드|릴| 수| 있습니다|.| 궁|금|한| 점|이| 있|으면| 언제|든|지| 말씀|해| 주세요|!||"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"session_id\": \"abc2\"}}\n",
    "for r in with_message_history.stream(\n",
    "    [HumanMessage(content = \"내가 어느 나라 사람인지 맞춰보고, 그 나라의 문화에 대해 말해봐\")],\n",
    "    config=config,\n",
    "):\n",
    "    print(r.content, end=\"|\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
